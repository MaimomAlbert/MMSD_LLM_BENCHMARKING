{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2680ff89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix)\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9f3c713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "    labels = [\"0\", \"1\"]\n",
    "    mapping = {label: idx for idx, label in enumerate(labels)}\n",
    "    \n",
    "    def map_func(x):\n",
    "        return mapping.get(x, -1)  # Map to -1 if not found, but should not occur with correct data\n",
    "    \n",
    "    y_true_mapped = np.vectorize(map_func)(y_true)\n",
    "    y_pred_mapped = np.vectorize(map_func)(y_pred)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true=y_true_mapped, y_pred=y_pred_mapped)\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    # Generate accuracy report\n",
    "    unique_labels = set(y_true_mapped)  # Get unique labels\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        label_indices = [i for i in range(len(y_true_mapped)) if y_true_mapped[i] == label]\n",
    "        label_y_true = [y_true_mapped[i] for i in label_indices]\n",
    "        label_y_pred = [y_pred_mapped[i] for i in label_indices]\n",
    "        label_accuracy = accuracy_score(label_y_true, label_y_pred)\n",
    "        print(f'Accuracy for label {labels[label]}: {label_accuracy:.4f}')\n",
    "        \n",
    "    # Generate classification report\n",
    "    class_report = classification_report(y_true=y_true_mapped, y_pred=y_pred_mapped, target_names=labels, labels=list(range(len(labels))), digits=4)\n",
    "    print('\\nClassification Report:')\n",
    "    print(class_report)\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true=y_true_mapped, y_pred=y_pred_mapped, labels=list(range(len(labels))))\n",
    "    print('\\nConfusion Matrix:')\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73afb2b9",
   "metadata": {},
   "source": [
    "### Performance of Idefics2 9B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37ce50ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "idefics_df = pd.read_json('/home/gpuuser3/sinngam_albert/work/mllm_finetune/idefics2_9B_test_predictions.json', dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e22121c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_id', 'text', 'label', 'image_path', 'question',\n",
       "       'idefics2_response', 'idefics2_label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idefics_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8d91edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idefics2_label\n",
       "0    1501\n",
       "1     908\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idefics_df['idefics2_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f62e98fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7090\n",
      "Accuracy for label 0: 0.7915\n",
      "Accuracy for label 1: 0.5998\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7235    0.7915    0.7560      1372\n",
      "           1     0.6850    0.5998    0.6396      1037\n",
      "\n",
      "    accuracy                         0.7090      2409\n",
      "   macro avg     0.7043    0.6957    0.6978      2409\n",
      "weighted avg     0.7069    0.7090    0.7059      2409\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1086  286]\n",
      " [ 415  622]]\n"
     ]
    }
   ],
   "source": [
    "evaluate(idefics_df['label'].values, idefics_df['idefics2_label'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d8aa08",
   "metadata": {},
   "source": [
    "### Performance test of Llava 1.6 Vicuna 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af7f4083",
   "metadata": {},
   "outputs": [],
   "source": [
    "vic_df = pd.read_json('/home/gpuuser3/sinngam_albert/work/mllm_finetune/llava16_vicuna_7B_mmsd2_test_predictions.json', dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "llava16_label\n",
       "0    1442\n",
       "1     967\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vic_df['llava16_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99298f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7186\n",
      "Accuracy for label 0: 0.7784\n",
      "Accuracy for label 1: 0.6393\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7406    0.7784    0.7591      1372\n",
      "           1     0.6856    0.6393    0.6617      1037\n",
      "\n",
      "    accuracy                         0.7186      2409\n",
      "   macro avg     0.7131    0.7089    0.7104      2409\n",
      "weighted avg     0.7170    0.7186    0.7171      2409\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1068  304]\n",
      " [ 374  663]]\n"
     ]
    }
   ],
   "source": [
    "evaluate(vic_df['label'].tolist(), vic_df['llava16_label'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4183d8cc",
   "metadata": {},
   "source": [
    "### Performance test on LLama 3.2 11B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3aa083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "547fb1f5",
   "metadata": {},
   "source": [
    "### Performance test on LLava 1.5 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ab9e9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "llava15_df = pd.read_json(\"/home/gpuuser3/sinngam_albert/work/mllm_finetune/llava15_7B_mmsd2_test_predictions.json\", dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ddb1438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>image_path</th>\n",
       "      <th>question</th>\n",
       "      <th>llava15_response</th>\n",
       "      <th>llava15_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862902619928506372</td>\n",
       "      <td>i am guessing # netflix no longer lets you gra...</td>\n",
       "      <td>1</td>\n",
       "      <td>/home/gpuuser3/sinngam_albert/datasets/mmsd2/d...</td>\n",
       "      <td>Classify the text &lt;i am guessing # netflix no ...</td>\n",
       "      <td>SARCASTIC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>892551658487631873</td>\n",
       "      <td>it 's the insensitive strikeouts at suntrust p...</td>\n",
       "      <td>1</td>\n",
       "      <td>/home/gpuuser3/sinngam_albert/datasets/mmsd2/d...</td>\n",
       "      <td>Classify the text &lt;it 's the insensitive strik...</td>\n",
       "      <td>SARCASTIC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>853143461360480256</td>\n",
       "      <td>following the path of the river calder , so .....</td>\n",
       "      <td>1</td>\n",
       "      <td>/home/gpuuser3/sinngam_albert/datasets/mmsd2/d...</td>\n",
       "      <td>Classify the text &lt;following the path of the r...</td>\n",
       "      <td>NOT SARCASTIC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>918423568823840768</td>\n",
       "      <td># westernsahara # authority has no lessons 2ge...</td>\n",
       "      <td>1</td>\n",
       "      <td>/home/gpuuser3/sinngam_albert/datasets/mmsd2/d...</td>\n",
       "      <td>Classify the text &lt;# westernsahara # authority...</td>\n",
       "      <td>SARCASTIC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>731617467718610944</td>\n",
       "      <td>hey &lt;user&gt; great sale !</td>\n",
       "      <td>1</td>\n",
       "      <td>/home/gpuuser3/sinngam_albert/datasets/mmsd2/d...</td>\n",
       "      <td>Classify the text &lt;hey &lt;user&gt; great sale !&gt; an...</td>\n",
       "      <td>NOT SARCASTIC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             image_id                                               text  \\\n",
       "0  862902619928506372  i am guessing # netflix no longer lets you gra...   \n",
       "1  892551658487631873  it 's the insensitive strikeouts at suntrust p...   \n",
       "2  853143461360480256  following the path of the river calder , so .....   \n",
       "3  918423568823840768  # westernsahara # authority has no lessons 2ge...   \n",
       "4  731617467718610944                            hey <user> great sale !   \n",
       "\n",
       "  label                                         image_path  \\\n",
       "0     1  /home/gpuuser3/sinngam_albert/datasets/mmsd2/d...   \n",
       "1     1  /home/gpuuser3/sinngam_albert/datasets/mmsd2/d...   \n",
       "2     1  /home/gpuuser3/sinngam_albert/datasets/mmsd2/d...   \n",
       "3     1  /home/gpuuser3/sinngam_albert/datasets/mmsd2/d...   \n",
       "4     1  /home/gpuuser3/sinngam_albert/datasets/mmsd2/d...   \n",
       "\n",
       "                                            question llava15_response  \\\n",
       "0  Classify the text <i am guessing # netflix no ...        SARCASTIC   \n",
       "1  Classify the text <it 's the insensitive strik...        SARCASTIC   \n",
       "2  Classify the text <following the path of the r...    NOT SARCASTIC   \n",
       "3  Classify the text <# westernsahara # authority...        SARCASTIC   \n",
       "4  Classify the text <hey <user> great sale !> an...    NOT SARCASTIC   \n",
       "\n",
       "  llava15_label  \n",
       "0             1  \n",
       "1             1  \n",
       "2             0  \n",
       "3             1  \n",
       "4             0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llava15_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6513\n",
      "Accuracy for label 0: 0.5466\n",
      "Accuracy for label 1: 0.7898\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7748    0.5466    0.6410      1372\n",
      "           1     0.5684    0.7898    0.6610      1037\n",
      "\n",
      "    accuracy                         0.6513      2409\n",
      "   macro avg     0.6716    0.6682    0.6510      2409\n",
      "weighted avg     0.6859    0.6513    0.6496      2409\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[750 622]\n",
      " [218 819]]\n"
     ]
    }
   ],
   "source": [
    "evaluate(llava15_df['label'], llava15_df['llava15_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22300e84",
   "metadata": {},
   "source": [
    "### Performance test on LLava 1.6 Mistral 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdf3c12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "llava16_df = pd.read_json(\"/home/gpuuser3/sinngam_albert/work/mllm_finetune/llava16_mistral_7B_mmsd2_test_predictions.json\", dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bca0b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "llava16_label\n",
       "1    1497\n",
       "0     912\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llava16_df['llava16_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7484\n",
      "Accuracy for label 0: 0.6115\n",
      "Accuracy for label 1: 0.9296\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9200    0.6115    0.7347      1372\n",
      "           1     0.6440    0.9296    0.7609      1037\n",
      "\n",
      "    accuracy                         0.7484      2409\n",
      "   macro avg     0.7820    0.7706    0.7478      2409\n",
      "weighted avg     0.8011    0.7484    0.7459      2409\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[839 533]\n",
      " [ 73 964]]\n"
     ]
    }
   ],
   "source": [
    "evaluate(\n",
    "    y_true=llava16_df['label'].tolist(),\n",
    "    y_pred=llava16_df['llava16_label'].tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79388c95",
   "metadata": {},
   "source": [
    "### Consistency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "341f01e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ivl_df = pd.read_json(\"/home/gpuuser3/sinngam_albert/work/internvl_ft/inference_test/internvl25_8B_mmsd2_test_predictions.json\", dtype=\"str\")\n",
    "llama_df = pd.read_json(\"/home/gpuuser3/sinngam_albert/work/mllm_finetune/llama32_11b_mmsd2_test_predictions.json\", dtype=\"str\")\n",
    "mistral_df = pd.read_json(\"/home/gpuuser3/sinngam_albert/work/mllm_finetune/llava16_mistral_7B_mmsd2_test_predictions.json\", dtype=\"str\")\n",
    "vic_df = pd.read_json(\"/home/gpuuser3/sinngam_albert/work/mllm_finetune/llava16_vicuna_7B_mmsd2_test_predictions.json\", dtype=\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7eee86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Exact consistency (2 Models)\n",
      "{'all_model_consistency': 78.74636778746368, 'all_model_consistency_against_truth': 64.00996264009963, 'conistency_of_label_0_samples': 81.04956268221575, 'conistency_of_label_1_samples': 75.69913211186113}\n",
      "{'all_model_consistency': 75.79908675799086, 'all_model_consistency_against_truth': 60.68908260689082, 'conistency_of_label_0_samples': 79.1545189504373, 'conistency_of_label_1_samples': 71.35969141755064}\n",
      "{'all_model_consistency': 81.7766708177667, 'all_model_consistency_against_truth': 65.17227065172271, 'conistency_of_label_0_samples': 81.26822157434403, 'conistency_of_label_1_samples': 82.44937319189971}\n",
      "{'all_model_consistency': 77.1274387712744, 'all_model_consistency_against_truth': 62.26650062266501, 'conistency_of_label_0_samples': 81.92419825072886, 'conistency_of_label_1_samples': 70.7810993249759}\n",
      "{'all_model_consistency': 77.04441677044417, 'all_model_consistency_against_truth': 63.71938563719386, 'conistency_of_label_0_samples': 77.76967930029156, 'conistency_of_label_1_samples': 76.08486017357762}\n",
      "{'all_model_consistency': 74.34620174346202, 'all_model_consistency_against_truth': 60.52303860523038, 'conistency_of_label_0_samples': 78.2069970845481, 'conistency_of_label_1_samples': 69.23818707810993}\n",
      "{'all_model_consistency': 69.6969696969697, 'all_model_consistency_against_truth': 57.16064757160647, 'conistency_of_label_0_samples': 73.76093294460642, 'conistency_of_label_1_samples': 64.32015429122468}\n",
      "{'all_model_consistency': 72.35367372353674, 'all_model_consistency_against_truth': 59.40224159402242, 'conistency_of_label_0_samples': 77.69679300291546, 'conistency_of_label_1_samples': 65.28447444551591}\n",
      "{'all_model_consistency': 67.24782067247821, 'all_model_consistency_against_truth': 56.496471564964715, 'conistency_of_label_0_samples': 69.46064139941691, 'conistency_of_label_1_samples': 64.32015429122468}\n",
      "{'all_model_consistency': 71.39892071398921, 'all_model_consistency_against_truth': 57.077625570776256, 'conistency_of_label_0_samples': 75.36443148688046, 'conistency_of_label_1_samples': 66.15236258437801}\n",
      "### Exact consistency (3 Models)\n",
      "{'all_model_consistency': 68.78372768783728, 'all_model_consistency_against_truth': 57.907845579078455, 'conistency_of_label_0_samples': 70.04373177842565, 'conistency_of_label_1_samples': 67.11668273866924}\n",
      "{'all_model_consistency': 65.83644665836447, 'all_model_consistency_against_truth': 55.33416355334163, 'conistency_of_label_0_samples': 71.06413994169097, 'conistency_of_label_1_samples': 58.919961427193826}\n",
      "{'all_model_consistency': 60.39850560398505, 'all_model_consistency_against_truth': 51.515151515151516, 'conistency_of_label_0_samples': 66.25364431486881, 'conistency_of_label_1_samples': 52.65188042430087}\n",
      "{'all_model_consistency': 65.96097965960979, 'all_model_consistency_against_truth': 55.33416355334163, 'conistency_of_label_0_samples': 69.31486880466473, 'conistency_of_label_1_samples': 61.52362584378014}\n",
      "{'all_model_consistency': 59.3607305936073, 'all_model_consistency_against_truth': 51.05853051058531, 'conistency_of_label_0_samples': 62.244897959183675, 'conistency_of_label_1_samples': 55.54484088717454}\n",
      "{'all_model_consistency': 58.44748858447488, 'all_model_consistency_against_truth': 49.48111249481112, 'conistency_of_label_0_samples': 64.1399416909621, 'conistency_of_label_1_samples': 50.91610414657667}\n",
      "{'all_model_consistency': 64.2590286425903, 'all_model_consistency_against_truth': 54.87754254877542, 'conistency_of_label_0_samples': 68.95043731778425, 'conistency_of_label_1_samples': 58.05207328833173}\n",
      "{'all_model_consistency': 58.32295558322955, 'all_model_consistency_against_truth': 50.850975508509755, 'conistency_of_label_0_samples': 62.46355685131195, 'conistency_of_label_1_samples': 52.84474445515911}\n",
      "{'all_model_consistency': 60.44001660440017, 'all_model_consistency_against_truth': 51.141552511415526, 'conistency_of_label_0_samples': 67.4927113702624, 'conistency_of_label_1_samples': 51.10896817743491}\n",
      "{'all_model_consistency': 56.496471564964715, 'all_model_consistency_against_truth': 49.356579493565796, 'conistency_of_label_0_samples': 61.51603498542274, 'conistency_of_label_1_samples': 49.85535197685632}\n",
      "### Exact consistency (4 Models)\n",
      "{'all_model_consistency': 58.98713158987131, 'all_model_consistency_against_truth': 51.01701951017019, 'conistency_of_label_0_samples': 63.62973760932945, 'conistency_of_label_1_samples': 52.84474445515911}\n",
      "{'all_model_consistency': 53.50767953507679, 'all_model_consistency_against_truth': 46.94894146948941, 'conistency_of_label_0_samples': 58.09037900874635, 'conistency_of_label_1_samples': 47.44455159112825}\n",
      "{'all_model_consistency': 53.17559153175592, 'all_model_consistency_against_truth': 46.035699460356994, 'conistency_of_label_0_samples': 60.204081632653065, 'conistency_of_label_1_samples': 43.876567020250725}\n",
      "{'all_model_consistency': 51.72270651722707, 'all_model_consistency_against_truth': 45.579078455790786, 'conistency_of_label_0_samples': 57.06997084548105, 'conistency_of_label_1_samples': 44.6480231436837}\n",
      "{'all_model_consistency': 51.598173515981735, 'all_model_consistency_against_truth': 45.745122457451224, 'conistency_of_label_0_samples': 58.01749271137027, 'conistency_of_label_1_samples': 43.10511089681774}\n",
      "### Exact consistency (5 Models)\n",
      "{'all_model_consistency': 48.111249481112495, 'all_model_consistency_against_truth': 42.839352428393525, 'conistency_of_label_0_samples': 54.59183673469388, 'conistency_of_label_1_samples': 39.537126325940214}\n"
     ]
    }
   ],
   "source": [
    "def check_consistencyN_with_truth(model_preds, tL):\n",
    "    \"\"\"\n",
    "    model_preds: List of lists, where each inner list is the predictions from one model.\n",
    "    tL: Ground truth labels (list of strings, '0' or '1')\n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "\n",
    "    total = len(tL)\n",
    "    match_all = 0\n",
    "    match_all_with_truth = 0\n",
    "\n",
    "    match_0 = match_1 = 0\n",
    "    total_0 = total_1 = 0\n",
    "\n",
    "    num_models = len(model_preds)\n",
    "\n",
    "    for preds in zip(*model_preds, tL):\n",
    "        *model_labels, truth = preds\n",
    "\n",
    "        if truth == '0':\n",
    "            total_0 += 1\n",
    "        else:\n",
    "            total_1 += 1\n",
    "\n",
    "        # Check if all model predictions agree\n",
    "        if all(label == model_labels[0] for label in model_labels):\n",
    "            match_all += 1\n",
    "            if truth == '0':\n",
    "                match_0 += 1\n",
    "            else:\n",
    "                match_1 += 1\n",
    "                \n",
    "            if model_labels[0] == truth:\n",
    "                match_all_with_truth += 1\n",
    "\n",
    "\n",
    "    overall_consistency = (match_all / total) * 100 if total > 0 else 0\n",
    "    overall_truth_consistency = (match_all_with_truth / total) * 100 if total > 0 else 0\n",
    "    consistency_0 = (match_0 / total_0) * 100 if total_0 > 0 else 0\n",
    "    consistency_1 = (match_1 / total_1) * 100 if total_1 > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"all_model_consistency\": overall_consistency,\n",
    "        \"all_model_consistency_against_truth\": overall_truth_consistency,\n",
    "        \"conistency_of_label_0_samples\": consistency_0,\n",
    "        \"conistency_of_label_1_samples\": consistency_1\n",
    "    }\n",
    "\n",
    "print(\"### Exact consistency (2 Models)\")\n",
    "print(check_consistencyN_with_truth(\n",
    "    [ivl_df['internvl_label'], llama_df['llama_label']],\n",
    "    ivl_df['label']\n",
    "))\n",
    "print(check_consistencyN_with_truth(\n",
    "    [ivl_df['internvl_label'], vic_df['llava16_label']],\n",
    "    ivl_df['label']\n",
    "))\n",
    "print(check_consistencyN_with_truth(\n",
    "    [ivl_df['internvl_label'], mistral_df['llava16_label']],\n",
    "    ivl_df['label']\n",
    "))\n",
    "print(check_consistencyN_with_truth(\n",
    "    [llama_df['llama_label'], vic_df['llava16_label']],\n",
    "    ivl_df['label']\n",
    "))\n",
    "print(check_consistencyN_with_truth(\n",
    "    [llama_df['llama_label'], mistral_df['llava16_label']],\n",
    "    ivl_df['label']\n",
    "))\n",
    "print(check_consistencyN_with_truth(\n",
    "    [vic_df['llava16_label'], mistral_df['llava16_label']],\n",
    "    ivl_df['label']\n",
    "))\n",
    "print(check_consistencyN_with_truth(\n",
    "    [ivl_df['internvl_label'], idefics_df['idefics2_label']],\n",
    "    ivl_df['label']\n",
    "))\n",
    "print(check_consistencyN_with_truth(\n",
    "    [llama_df['llama_label'], idefics_df['idefics2_label']], \n",
    "    ivl_df['label']\n",
    "))\n",
    "print(check_consistencyN_with_truth(\n",
    "    [mistral_df['llava16_label'], idefics_df['idefics2_label']], \n",
    "    ivl_df['label']\n",
    "))\n",
    "print(check_consistencyN_with_truth(\n",
    "    [vic_df['llava16_label'], idefics_df['idefics2_label']], \n",
    "    ivl_df['label']\n",
    "))\n",
    "\n",
    "print(\"### Exact consistency (3 Models)\")\n",
    "print(check_consistencyN_with_truth(\n",
    "    [ivl_df['internvl_label'], llama_df['llama_label'], mistral_df['llava16_label']],\n",
    "    ivl_df['label']\n",
    "))\n",
    "print(check_consistencyN_with_truth(\n",
    "    [ivl_df['internvl_label'], llama_df['llama_label'], vic_df['llava16_label']],\n",
    "    ivl_df['label']\n",
    "))\n",
    "print(check_consistencyN_with_truth(\n",
    "    [ivl_df['internvl_label'], llama_df['llama_label'], idefics_df['idefics2_label']],\n",
    "    ivl_df['label']\n",
    "))\n",
    "print(check_consistencyN_with_truth(\n",
    "    [ivl_df['internvl_label'], mistral_df['llava16_label'], vic_df['llava16_label']],\n",
    "    ivl_df['label']\n",
    "))\n",
    "print(check_consistencyN_with_truth(\n",
    "    [ivl_df['internvl_label'], mistral_df['llava16_label'], idefics_df['idefics2_label']],\n",
    "    ivl_df['label']\n",
    "))\n",
    "print(check_consistencyN_with_truth(\n",
    "    [ivl_df['internvl_label'], vic_df['llava16_label'], idefics_df['idefics2_label']],\n",
    "    ivl_df['label']\n",
    "))\n",
    "print(check_consistencyN_with_truth(\n",
    "    [llama_df['llama_label'], mistral_df['llava16_label'], vic_df['llava16_label']],\n",
    "    ivl_df['label']\n",
    "))\n",
    "print(check_consistencyN_with_truth(\n",
    "    [llama_df['llama_label'], mistral_df['llava16_label'], idefics_df['idefics2_label']],\n",
    "    ivl_df['label']\n",
    "))\n",
    "print(check_consistencyN_with_truth(\n",
    "    [llama_df['llama_label'], vic_df['llava16_label'], idefics_df['idefics2_label']],\n",
    "    ivl_df['label']\n",
    "))\n",
    "print(check_consistencyN_with_truth(\n",
    "    [mistral_df['llava16_label'], vic_df['llava16_label'], idefics_df['idefics2_label']],\n",
    "    ivl_df['label']\n",
    "))\n",
    "\n",
    "print(\"### Exact consistency (4 Models)\")\n",
    "print(check_consistencyN_with_truth(\n",
    "    [ivl_df['internvl_label'], llama_df['llama_label'], mistral_df['llava16_label'], vic_df['llava16_label']],\n",
    "    ivl_df['label']\n",
    "))\n",
    "print(check_consistencyN_with_truth(\n",
    "    [ivl_df['internvl_label'], llama_df['llama_label'], mistral_df['llava16_label'], idefics_df['idefics2_label']],\n",
    "    ivl_df['label']\n",
    "))\n",
    "print(check_consistencyN_with_truth(\n",
    "    [ivl_df['internvl_label'], llama_df['llama_label'], vic_df['llava16_label'], idefics_df['idefics2_label']],\n",
    "    ivl_df['label']\n",
    "))\n",
    "\n",
    "print(check_consistencyN_with_truth(\n",
    "    [ivl_df['internvl_label'], mistral_df['llava16_label'], vic_df['llava16_label'], idefics_df['idefics2_label']],\n",
    "    ivl_df['label']\n",
    "))\n",
    "\n",
    "print(check_consistencyN_with_truth(\n",
    "    [llama_df['llama_label'], mistral_df['llava16_label'], vic_df['llava16_label'], idefics_df['idefics2_label']],\n",
    "    ivl_df['label']\n",
    "))\n",
    "\n",
    "print(\"### Exact consistency (5 Models)\")\n",
    "print(check_consistencyN_with_truth(\n",
    "    [ivl_df['internvl_label'], llama_df['llama_label'], mistral_df['llava16_label'], vic_df['llava16_label'], idefics_df['idefics2_label']],\n",
    "    ivl_df['label']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d427743a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Majority Vote Accuracy (5 Models)\n",
      "{'overall_accuracy': 77.91614777916148, 'class_0_accuracy': 75.29154518950438, 'class_1_accuracy': 81.38862102217936}\n"
     ]
    }
   ],
   "source": [
    "def majority_vote_accuracyN(model_preds, tL):\n",
    "    \"\"\"\n",
    "    model_preds: List of lists, where each inner list is the predictions from one model (strings or ints '0'/'1')\n",
    "    tL: Ground truth labels (list of strings or ints: '0' or '1')\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    correct_0 = 0\n",
    "    correct_1 = 0\n",
    "    total_0 = 0\n",
    "    total_1 = 0\n",
    "\n",
    "    num_models = len(model_preds)\n",
    "    \n",
    "    for preds in zip(*model_preds, tL):\n",
    "        *model_labels, truth = preds\n",
    "        model_labels = list(map(int, model_labels))\n",
    "        truth = int(truth)\n",
    "\n",
    "        vote_sum = sum(model_labels)\n",
    "        vote = 1 if vote_sum >= (num_models / 2) else 0\n",
    "\n",
    "        if truth == 0:\n",
    "            total_0 += 1\n",
    "            if vote == truth:\n",
    "                correct_0 += 1\n",
    "        else:\n",
    "            total_1 += 1\n",
    "            if vote == truth:\n",
    "                correct_1 += 1\n",
    "\n",
    "        if vote == truth:\n",
    "            correct += 1\n",
    "\n",
    "    total = len(tL)\n",
    "    overall_accuracy = (correct / total) * 100 if total > 0 else 0\n",
    "    class_0_accuracy = (correct_0 / total_0) * 100 if total_0 > 0 else 0\n",
    "    class_1_accuracy = (correct_1 / total_1) * 100 if total_1 > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"overall_accuracy\": overall_accuracy,\n",
    "        \"class_0_accuracy\": class_0_accuracy,\n",
    "        \"class_1_accuracy\": class_1_accuracy\n",
    "    }\n",
    "\n",
    "print(\"### Majority Vote Accuracy (5 Models)\")\n",
    "print(majority_vote_accuracyN(\n",
    "    [ivl_df['internvl_label'], llama_df['llama_label'], mistral_df['llava16_label'], vic_df['llava16_label'], idefics_df['idefics2_label']],\n",
    "    ivl_df['label']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa75df07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idefics2-sinngam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
