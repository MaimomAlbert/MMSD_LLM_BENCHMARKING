{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2b50b67",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f30c9f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b9c4956",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/sinngamkhaidem/Developer/mllm-based-mmsd-osint/mllm_finetune/gpt_predictions/selected_samples_osint_mmsd.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73a78220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>major_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1mau6q6</td>\n",
       "      <td>look into my eyes.. and give treats üëÄ</td>\n",
       "      <td>aww</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>h8vdb8</td>\n",
       "      <td>lol sex and weed number funny</td>\n",
       "      <td>FellowKids</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m5xe5w</td>\n",
       "      <td>kenyon martin called out jeremy lin for his ha...</td>\n",
       "      <td>popular</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5wg0gy</td>\n",
       "      <td>i can see it coming</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1mbsoge</td>\n",
       "      <td>this right here? peak love üòç</td>\n",
       "      <td>popular</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>qzejm0</td>\n",
       "      <td>why stop at just one stick up the ass when you...</td>\n",
       "      <td>technicallythetruth</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1ith0ez</td>\n",
       "      <td>tv bad</td>\n",
       "      <td>im14andthisisdeep</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lxiydt</td>\n",
       "      <td>throwback to when my goat was standing on my d...</td>\n",
       "      <td>AnimalsBeingJerks</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1mbpyzr</td>\n",
       "      <td>meirl</td>\n",
       "      <td>popular</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kylmnj</td>\n",
       "      <td>found a patch of moss behind a loading dock th...</td>\n",
       "      <td>mildlyinteresting</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rrcyim</td>\n",
       "      <td>this glass has clear water in it, but your bra...</td>\n",
       "      <td>notinteresting</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gu3xwh</td>\n",
       "      <td>sugar ring by meret oppenheim</td>\n",
       "      <td>ATBGE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9wpd7q</td>\n",
       "      <td>yes i also point a gun at my teacher</td>\n",
       "      <td>im14andthisisdeep</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>t5jtck</td>\n",
       "      <td>have a rest from all the bad news with some la...</td>\n",
       "      <td>BeAmazed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1ktcjdp</td>\n",
       "      <td>mom vs iphone</td>\n",
       "      <td>im14andthisisdeep</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1m70zt3</td>\n",
       "      <td>i have a fox family living near my summer cabi...</td>\n",
       "      <td>aww</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1ba8tzw</td>\n",
       "      <td>da fuck?!</td>\n",
       "      <td>trippingthroughtime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ucftvn</td>\n",
       "      <td>the clone wars be like: \"am i a joke to you\"</td>\n",
       "      <td>PrequelMemes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>lrcexp</td>\n",
       "      <td>camera money gun</td>\n",
       "      <td>im14andthisisdeep</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1mbji7q</td>\n",
       "      <td>winking üòâ haha</td>\n",
       "      <td>aww</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                                               text  \\\n",
       "0   1mau6q6              look into my eyes.. and give treats üëÄ   \n",
       "1    h8vdb8                      lol sex and weed number funny   \n",
       "2    m5xe5w  kenyon martin called out jeremy lin for his ha...   \n",
       "3    5wg0gy                                i can see it coming   \n",
       "4   1mbsoge                       this right here? peak love üòç   \n",
       "5    qzejm0  why stop at just one stick up the ass when you...   \n",
       "6   1ith0ez                                             tv bad   \n",
       "7    lxiydt  throwback to when my goat was standing on my d...   \n",
       "8   1mbpyzr                                              meirl   \n",
       "9    kylmnj  found a patch of moss behind a loading dock th...   \n",
       "10   rrcyim  this glass has clear water in it, but your bra...   \n",
       "11   gu3xwh                      sugar ring by meret oppenheim   \n",
       "12   9wpd7q               yes i also point a gun at my teacher   \n",
       "13   t5jtck  have a rest from all the bad news with some la...   \n",
       "14  1ktcjdp                                      mom vs iphone   \n",
       "15  1m70zt3  i have a fox family living near my summer cabi...   \n",
       "16  1ba8tzw                                          da fuck?!   \n",
       "17   ucftvn       the clone wars be like: \"am i a joke to you\"   \n",
       "18   lrcexp                                   camera money gun   \n",
       "19  1mbji7q                                     winking üòâ haha   \n",
       "\n",
       "              subreddit  major_label  \n",
       "0                   aww            0  \n",
       "1            FellowKids            1  \n",
       "2               popular            0  \n",
       "3               sarcasm            1  \n",
       "4               popular            0  \n",
       "5   technicallythetruth            1  \n",
       "6     im14andthisisdeep            1  \n",
       "7     AnimalsBeingJerks            0  \n",
       "8               popular            1  \n",
       "9     mildlyinteresting            0  \n",
       "10       notinteresting            1  \n",
       "11                ATBGE            0  \n",
       "12    im14andthisisdeep            1  \n",
       "13             BeAmazed            0  \n",
       "14    im14andthisisdeep            1  \n",
       "15                  aww            0  \n",
       "16  trippingthroughtime            1  \n",
       "17         PrequelMemes            1  \n",
       "18    im14andthisisdeep            1  \n",
       "19                  aww            0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edd7406",
   "metadata": {},
   "source": [
    "### Replace username and subreddits with tokens. And remove emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a02ea586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    text = row[\"text\"]\n",
    "    user_cleaned_text = re.sub(r'/?u/\\S+', '<user>', text)\n",
    "    subreddit_cleaned_text = re.sub(r'/?r/\\S+', '<subreddit>', user_cleaned_text)\n",
    "    emoji_removed = emoji.replace_emoji(subreddit_cleaned_text, replace='')\n",
    "    df.loc[idx, \"text\"] = emoji_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23d84419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>major_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1mau6q6</td>\n",
       "      <td>look into my eyes.. and give treats</td>\n",
       "      <td>aww</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>h8vdb8</td>\n",
       "      <td>lol sex and weed number funny</td>\n",
       "      <td>FellowKids</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m5xe5w</td>\n",
       "      <td>kenyon martin called out jeremy lin for his ha...</td>\n",
       "      <td>popular</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5wg0gy</td>\n",
       "      <td>i can see it coming</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1mbsoge</td>\n",
       "      <td>this right here? peak love</td>\n",
       "      <td>popular</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id                                               text   subreddit  \\\n",
       "0  1mau6q6               look into my eyes.. and give treats          aww   \n",
       "1   h8vdb8                      lol sex and weed number funny  FellowKids   \n",
       "2   m5xe5w  kenyon martin called out jeremy lin for his ha...     popular   \n",
       "3   5wg0gy                                i can see it coming     sarcasm   \n",
       "4  1mbsoge                        this right here? peak love      popular   \n",
       "\n",
       "   major_label  \n",
       "0            0  \n",
       "1            1  \n",
       "2            0  \n",
       "3            1  \n",
       "4            0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c080037d",
   "metadata": {},
   "source": [
    "# Splitting into train, valid and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "914dd254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"/Users/sinngamkhaidem/Developer/mllm-based-mmsd-osint/mllm_finetune/gpt_predictions/selected_samples_osint_mmsd_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6215edaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23288, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caf7c932",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = df[df[\"label\"] == 1]\n",
    "df_neg = df[df[\"label\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dcbbce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_splits = {}\n",
    "neg_splits = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfc5a925",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, group in df_pos.groupby(\"subreddit\"):\n",
    "    train, test = train_test_split(group, test_size=0.2, random_state=42)\n",
    "    valid, test = train_test_split(test, test_size=0.5, random_state=42)\n",
    "    pos_splits[key] = [train.reset_index(drop = True), valid.reset_index(drop=True), test.reset_index(drop=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7edb730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit\n",
       "aww                      842\n",
       "popular                 1054\n",
       "ATBGE                    642\n",
       "mildlyinteresting       2063\n",
       "notinteresting           735\n",
       "popculturechat           313\n",
       "Damnthatsinteresting     667\n",
       "technicallythetruth      130\n",
       "PrequelMemes             177\n",
       "pics                    1120\n",
       "FellowKids               285\n",
       "mildlyinfuriating        631\n",
       "BeAmazed                 382\n",
       "funny                    175\n",
       "AnimalsBeingJerks        144\n",
       "memes                     47\n",
       "im14andthisisdeep        178\n",
       "madlads                   77\n",
       "FUCKYOUINPARTICULAR      124\n",
       "PeopleFuckingDying       192\n",
       "sports                   114\n",
       "trippingthroughtime       62\n",
       "rareinsults               61\n",
       "sarcasm                   68\n",
       "qualityrareinsults         5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_neg[\"subreddit\"].value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4561947c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=1, test_size=0.5 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, group \u001b[38;5;129;01min\u001b[39;00m df_neg\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubreddit\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      2\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m train_test_split(group, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m45\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     valid, test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m45\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     neg_splits[key] \u001b[38;5;241m=\u001b[39m [train\u001b[38;5;241m.\u001b[39mreset_index(drop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m), valid\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), test\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)]\n",
      "File \u001b[0;32m/opt/miniconda3/envs/mllm-mmsd/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:218\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    214\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    215\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    216\u001b[0m         )\n\u001b[1;32m    217\u001b[0m     ):\n\u001b[0;32m--> 218\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    228\u001b[0m     )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/mllm-mmsd/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2919\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2916\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m   2918\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 2919\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2920\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[1;32m   2921\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2923\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   2924\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/mllm-mmsd/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2499\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2496\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[1;32m   2498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2499\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2500\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2501\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2502\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[1;32m   2503\u001b[0m     )\n\u001b[1;32m   2505\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=1, test_size=0.5 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "for key, group in df_neg.groupby(\"subreddit\"):\n",
    "    train, test = train_test_split(group, test_size=0.2, random_state=45)\n",
    "    valid, test = train_test_split(test, test_size=0.5, random_state=45)\n",
    "    neg_splits[key] = [train.reset_index(drop = True), valid.reset_index(drop=True), test.reset_index(drop=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b6d6379f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18617, 4)\n",
      "(2330, 4)\n",
      "(2341, 4)\n"
     ]
    }
   ],
   "source": [
    "train = None\n",
    "valid = None\n",
    "test = None\n",
    "for key, value in splits.items():\n",
    "    train = pd.concat([train, value[0]])\n",
    "    valid = pd.concat([valid, value[1]])\n",
    "    test = pd.concat([test, value[2]])\n",
    "print(train.shape)\n",
    "print(valid.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bd6d293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"/Users/sinngamkhaidem/Developer/mllm-based-mmsd-osint/mllm_finetune/gpt_predictions/train.csv\", index=False)\n",
    "valid.to_csv(\"/Users/sinngamkhaidem/Developer/mllm-based-mmsd-osint/mllm_finetune/gpt_predictions/valid.csv\", index=False)\n",
    "test.to_csv(\"/Users/sinngamkhaidem/Developer/mllm-based-mmsd-osint/mllm_finetune/gpt_predictions/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b22778d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_json(\"/Users/sinngamkhaidem/Developer/mllm-based-mmsd-osint/mllm_finetune/gpt_predictions/train.json\", orient=\"records\", lines=False)\n",
    "valid.to_json(\"/Users/sinngamkhaidem/Developer/mllm-based-mmsd-osint/mllm_finetune/gpt_predictions/valid.json\", orient=\"records\", lines=False)\n",
    "test.to_json(\"/Users/sinngamkhaidem/Developer/mllm-based-mmsd-osint/mllm_finetune/gpt_predictions/test.json\", orient=\"records\", lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801f9683",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllm-mmsd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
